{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton code for data\n",
    "\n",
    "class dataObject:\n",
    "    def __init__(self, data: NDArray, result, label): \n",
    "        self.data = data\n",
    "        self.result = result\n",
    "        self.label = label\n",
    "\n",
    "# type that is a numpy array of dataObjects\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy data for now \n",
    "# lets say we are looking at net study time(weekly) to class score\n",
    "# first a test object shown below\n",
    "x = dataObject(np.array([6, 2, 3, 6, 1, 0, 0, 7]), 88, \"Calculus\")\n",
    "myArr = np.array([x])\n",
    "myArr = np.append(myArr, dataObject(np.array([3, 4, 2, 3, 5, 2, 0, 0]), 66, \"Calculus\"))\n",
    "myArr = np.append(myArr, dataObject(np.array([3, 0, 0, 0, 4, 5, 3, 3]), 84, \"Calculus\"))\n",
    "myArr = np.append(myArr, dataObject(np.array([0, 0, 0, 0, 0, 0, 0, 0]), 45, \"Calculus\"))\n",
    "myArr = np.append(myArr, dataObject(np.array([0, 0, 0, 4, 5, 0, 0, 0]), 93, \"English\"))\n",
    "myArr = np.append(myArr, dataObject(np.array([0, 0, 0, 0, 0, 5, 0, 0]), 77, \"English\"))\n",
    "myArr = np.append(myArr, dataObject(np.array([0, 0, 0, 0, 0, 0, 0, 0]), 72, \"English\"))\n",
    "myArr = np.append(myArr, dataObject(np.array([1, 1, 1, 1, 1, 1, 1, 1]), 99, \"English\"))\n",
    "myArr = np.append(myArr, dataObject(np.array([0, 2, 0, 5, 0, 0, 5, 0]), 90, \"History\"))\n",
    "myArr = np.append(myArr, dataObject(np.array([2, 0, 0, 1, 0, 0, 0, 0]), 80, \"History\"))\n",
    "\n",
    "times = np.array([obj.data for obj in myArr])\n",
    "y_1 = np.array([obj.result for obj in myArr]) / 100.0\n",
    "\n",
    "sub = np.array([obj.label for obj in myArr])   \n",
    "encoder = LabelBinarizer()\n",
    "sub_enc = encoder.fit_transform(sub)\n",
    "x_1 = np.concatenate((times, sub_enc), axis=1)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just create a basic feed forward neural net with keras\n",
    "\n",
    "smallModel01 = Sequential()\n",
    "smallModel01.add(Dense(14, input_dim=x_1.shape[1], activation='relu'))\n",
    "smallModel01.add(Dense(45, activation='relu'))\n",
    "smallModel01.add(Dropout(0.5))\n",
    "smallModel01.add(Dense(22, activation='selu'))\n",
    "smallModel01.add(Dropout(.25)); \n",
    "smallModel01.add(Dense(3, activation='relu'))\n",
    "smallModel01.add(Dropout(.25)); \n",
    "\n",
    "smallModel01.add(Dense(45, activation='relu'))\n",
    "smallModel01.add(Dense(1, activation='linear'))\n",
    "\n",
    "smallModel01.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.1097\n",
      "Epoch 2/22\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.1074\n",
      "Epoch 3/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.1068\n",
      "Epoch 4/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0215 - mse: 0.0215 - mae: 0.1301\n",
      "Epoch 5/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0461 - mse: 0.0461 - mae: 0.1892\n",
      "Epoch 6/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.1185\n",
      "Epoch 7/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0641\n",
      "Epoch 8/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0985\n",
      "Epoch 9/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0565\n",
      "Epoch 10/22\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.1048\n",
      "Epoch 11/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.1043\n",
      "Epoch 12/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.1044\n",
      "Epoch 13/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0681\n",
      "Epoch 14/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.1039\n",
      "Epoch 15/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.1036\n",
      "Epoch 16/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0912\n",
      "Epoch 17/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0995\n",
      "Epoch 18/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0286 - mse: 0.0286 - mae: 0.1609\n",
      "Epoch 19/22\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.1025\n",
      "Epoch 20/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.1023\n",
      "Epoch 21/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.1009\n",
      "Epoch 22/22\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f413c3b9ae0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "smallModel01.fit(x_1[0:3], y_1[0:3], epochs=22, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
